---
title: "Llama 2"
contentType: "brief"
description: ""
author: "Jack Ivers"
publishDate: "2023-07-19T07:26:43-05:00"
draft: true
---

HN comments
Blocking apple:
 	
stu2b50 20 hours ago | root | parent | next [–]

I think more Apple. It's not like Google or Microsoft would want to use LLaMA when they have fully capable models themselves. I wouldn't be surprised if Amazon does as well.

Apple is the big laggard in terms of big tech and complex neural network models. 

	
	
samwillis 19 hours ago | root | parent | prev | next [–]

Apple would absolutely not want to use a competitors, or any other, public LLM. They want to own the whole stack, and will want to have their own secret source as part of it. It's not like they don't have the capital to invest in training...

reply
	
	
whimsicalism 19 hours ago | root | parent | next [–]

Apple does not have the capability to train a LLM currently.

	
	
samwillis 19 hours ago | root | parent | prev | next [–]

Apple would absolutely not want to use a competitors, or any other, public LLM. They want to own the whole stack, and will want to have their own secret source as part of it. It's not like they don't have the capital to invest in training...

reply
	
	
whimsicalism 19 hours ago | root | parent | next [–]

Apple does not have the capability to train a LLM currently.
	
	
NotAFood 19 hours ago | root | parent | next [–]

Apple has shown time and time again that they have the human capital and money to tackle massive projects discretely. It's already fairly well known that Apple's NLP experts from Siri have been reallocated to some secret project. They are more than capable of training an LLM but given their track record in other segments they probably want to wait for the technology to become more "polished" and give less hallucinated answers. They are likely also want the LLM to work locally (at least partially) on their devices using the Neural Engine which adds further engineering complexity to their project. They could even be timing the LLM's launch around a hardware release capable of running the model (M3, M4, etc...).

reply
	
	
yellow_postit 10 hours ago | root | parent | next [–]

Apple is a complete laggard in this space due to years of restrictions on research. They are hiring multiple “AI” roles now and they have the capital and focus to “eventually” catch up — but it is very much a catch-up game.

That said, they seem to prefer catchup waiting till others explore new tech they swoop in an (claim) to perfect it from a usability pov. I have no reason to suspect they won’t do the same here.

reply
	
	
amelius 18 hours ago | root | parent | prev | next [–]

Apple only has to slightly open their wallet to become a DL superpower.

reply
	
	
whimsicalism 18 hours ago | root | parent | prev | next [–]

I have not seen Apple demonstrate ML depth in their talent nor have I seen signs that they are hiring extensively for NLP depth.

They will soon be able to train an LLM because it simply has become commoditized, but they just are not a major player in this space at all.

reply
	
	
Jcowell 16 hours ago | root | parent | next [–]

> I have not seen Apple demonstrate ML depth in their talent

I thought the ml work they do in photos for text selection and facial recognition is pretty neat.

reply
	
	
layoric 13 hours ago | root | parent | prev | next [–]

Their approach is different, they build ML tech that runs on-device, so whatever they developed has to be able to run efficiently on iPhone/iPad etc.

I don’t think we will “hear” about Apple using LLMs either way because they will no doubt call it something different like they always have.

reply
	
	
zirgs 5 hours ago | root | parent | prev | next [–]

Why not? They have cash and they can rent a bunch of GPUs from Amazon.

reply
	
	
samwillis 19 hours ago | root | parent | prev | next [–]

I very much doubt that.

reply
	
	
smoldesu 18 hours ago | root | parent | next [–]

If they want to own the whole stack, I don't think they have much to work with. Their highest-end server chip is a duplex laptop SOC, with maxed-out memory that doesn't even match the lowest-end Grace CPU you can buy (nevermind a fully-networked GH200). Their consumer offerings are competitive, but I don't think Apple Silicon or CoreML is ready to seriously compete with Grace and CUDA.

reply
	
	
samwillis 18 hours ago | root | parent | next [–]

While Apple silicone may not be there for training, I think it's probably there for inference. I expect next years device models to launch with exclusive support for Apples own LLM based Siri.

reply
	
	
smoldesu 18 hours ago | root | parent | next [–]

Sure. Haswell CPUs from 2014 are "there" for inference if they have AVX support and 8gb of RAM. Inferencing isn't the problem though, not on M1 or Macbooks from 2016. Scaling a desirable (and hopefully open) GPGPU programming interface is. This is bottlenecked by both hardware and software decisions Apple has made, making a "home grown" competitive model much more unlikely in my eyes.

I agree that there is an incentive to put AI models on your OS. I just don't think Apple can own the whole stack if they want to play ball right now.

reply
	
	
xbmcuser 19 hours ago | root | parent | prev | next [–]

What makes you think that. Apple is the company that would be most successful at hiding something like this then introduce it as siri ai or something. Not that they are I am just saying Apple keeps everything close to its chest when it comes to products it might introduce in the future.

reply
	
	
whimsicalism 18 hours ago | root | parent | next [–]

I work in the field and they just are not hiring the people they need to be hiring.

reply
	
	
kossTKR 14 hours ago | root | parent | next [–]

Interesting. The very early adoption of the neural engines in all Apple products would make you think that they had something brewing. Same with the relatively capable m1/2 GPU's. Various models and stable diffusion runs suprisingly fast on these devices and could be optimised to run much, much faster if Apple actually cared, but they weirdly seem not to.

reply
	
	
reacharavindh 6 hours ago | root | parent | prev | next [–]

Considering how much Apple likes to retain control, I’m almost sure they won’t want to use someone else’s model even if it were free in every sense of the word.