---
title: "AI Coding Tools: Today: Context, Tomorrow: Agents"
contentType: "essay"
description: "An exploration of the latest AI-powered coding tools and their emphasis on context"
author: "Jack Ivers"
publishDate: "2024-09-03T19:54:00-05:00"
draft: true
categories: ["AI", "Programming"]
tags: ["AI coding", "Cody", "Codeium", "Cursor", "Devin"]
---

I've been taking a deep dive into AI coding tools recently. It all started with the [2024 AI Engineer Worlds Fair](https://www.ai.engineer/worldsfair/2024/schedule), which took place June 25-27. I had intended to follow along with the livestream, but my CTO day job intervened, and I found myself actually tracking down the [livestream recordings](https://www.youtube.com/@aiDotEngineer) in early July. The event had a track dedicated to coding tools ("CodeGen") [ADD LINK], which for me proved to be a goldmine.

Before watching the Worlds Fair videos, my AI Coding worldview could be summarized as

> ChatGPT 4+ is a great coding companion.

> Specialized AI coding tools (e.g. GitHub Copilot) aren't very useful.

Excellent talks by [LIST TALKS], along with an outstanding essay by Steve Yegge of Sourcegraph [ADD LINK], started reshaping my views, affirming some aspects, upending others. I began using tools like Cody and Cursor, and experienced firsthand just how great they are. And has often been the case over the past 24 months of the AI emergence, the announcements, releases, and demos just keep pouring in.

Here's my AI Coding worldview as of today:

> **The advent of GPT-4o and Claude 3.5 Sonnet completely tip the balance in favor of every developer using AI Coding tools.** Twice as fast, half the mistakes and missteps. Using AI Coding tools, regardless of developer skill level, is now an absolute no-brainer.

> These new models are **fantastic** coding companions; **but they're even more powerful when tightly integrated into the IDE**.

> **There's a lot more to today's AI Coding tools than autocomplete; they're fantastic. Don't let past experiences with Copilot sour you.**

> **Expanded context is the current state of the art in AI Coding tools.**

> **Agentic workflow tools, enabled by even greater context expansions, are beginning to arrive as we speak, and will revolutionize the already revolutionary.**

## CHOP (Chat Oriented Programming) and Cody

After watching the [Worlds Fair talk](https://www.youtube.com/watch?v=5zE2sMka620&t=18831) by Steve Yegge ([Sourcegraph](https://about.sourcegraph.com/) / [Cody](https://about.sourcegraph.com/cody)), I found my way to his essay [The Death of the Junior Developer](https://sourcegraph.com/blog/the-death-of-the-junior-developer). I loved his acronym CHOP -- Chat Oriented Programming -- a practice I experimented with in the GPT-3.5 era and increasingly relied on with the advent of GPT-4.

One of Yegge's key points in introducing CHOP is simply pointing out that Copilot-like autocomplete isn't the best AI can bring to the coding space. Pairing with a bright, deeply-read, inexhaustible coding assistant is a completely different and far more transformative experience than simply getting better autocompletes.

Another Yegge observation that strongly resonated: the arrival of GPT-4o changed the AI Coding game completely. The combination of twice as fast, with half the mistakes, radically changes the developer workflow. Two thresholds are crossed at once: "so fast I don't need to multitask" and "rarely fails with the dreaded LLM death spiral." 

Yegge's essay predated the arrival of Anthropic's Claude 3.5 Sonnet, which rivals or exceeds GPT-4o on speed and accuracy; yet another game-changing moment. We now have two superb coding models at our disposal.

Cody's CHOP innovation was tightly integrating the Chat part of CHOP into the IDE experience. So rather than the back-and-forth, copy-and-paste ChatGPT workflow I used throughout the GPT-4 era, now I've got chat right there in the IDE, aware of what I'm working on, and able to lay the code changes down right in the editor pane with no copy and paste pain. 

## Expanded Context and Cursor

[Cursor demo](https://www.youtube.com/watch?v=pAbRL0h_SNs)

Context
- Full codebase indexing
- Chat with codebase
- Adding context with @ commands

Cool features
- Inline Edit CMD-K
- Composer (CMD-I)
  - Multi-file AI coding
  - Avility to make files


### Cursor Composer (CMD-I)

[Composer video](https://www.youtube.com/watch?v=msHbQfhS3p8) [Another composer video](https://www.youtube.com/watch?v=msHbQfhS3p8)

TODO: Focus this section on cursor as an example of bigger, broader context (exemplified by @ commands), and two great features, in-place editing (CMD-K) and Composer (CMD-I).

[Cursor](https://www.cursor.com/) has emerged as a game-changer in the AI-assisted coding landscape, particularly in its approach to leveraging context. By forking Visual Studio Code, Cursor has created an IDE that feels familiar to developers while integrating powerful AI capabilities that go far beyond simple code completion.

### Context-Aware Coding

Cursor's standout feature is its ability to understand and utilize the broader context of your codebase. Unlike earlier AI coding assistants that focused on line-by-line suggestions, Cursor can analyze entire files, projects, and even external documentation to provide more relevant and sophisticated coding assistance.

A key component of Cursor's context-awareness is its innovative use of @ commands([1](https://docs.cursor.com/context/@-symbols/basic)). These commands allow developers to explicitly add various types of context to their queries:

1. @Files: Allows referencing entire files as context.
2. @Folders: Enables including entire folders in the context, especially useful for long-context chats.
3. @Code: Lets developers reference specific sections of code.
4. @Docs: Provides access to a set of third-party docs, which can be expanded with custom documentation.
5. @Codebase: Performs an advanced search through the indexed codebase for relevant code snippets.
6. @Web: Constructs a search query based on the context and searches the web for relevant information.

These @ commands give developers fine-grained control over the context provided to the AI, ensuring that it has the most relevant information to work with. For instance, a developer could use @Codebase to find relevant implementations across the project, @Docs to reference specific documentation, and @Web to fetch up-to-date information from online sources.

### Cursor Composer (CMD-I)

[Composer video](https://www.youtube.com/watch?v=msHbQfhS3p8)

### Flexible Model Selection

One of Cursor's unique strengths is its ability to work with multiple AI models, giving developers unprecedented control over their AI-assisted coding experience([2](https://docs.cursor.com/advanced/models)). This flexibility allows developers to choose the most appropriate model for their specific needs, primarily falling into two categories:

1. "Great-and-Fast" Models:
   - GPT-4o: OpenAI's latest model, offering state-of-the-art performance with impressive speed.
   - Claude 3.5 Sonnet: Anthropic's advanced model, known for its strong coding capabilities and quick responses.

2. "Extremely Fast" Models:
   - cursor-small: Cursor's custom model, optimized for rapid responses on simpler tasks.
   - gpt-4o-mini: A lightweight version of GPT-4o, designed for ultra-fast performance on less complex queries.

Developers can easily switch between these models using a dropdown menu or keyboard shortcuts. This feature is particularly useful for balancing between high-quality, context-rich assistance and rapid, on-the-fly coding support.

As Juan Stoppa notes in his [detailed review](https://jstoppa.com/posts/artificial-intelligence/fundamentals/code-smarter-not-harder-developing-with-cursor-and-claude-sonnet/post/), Cursor's integration with advanced language models like Claude 3.5 Sonnet allows for a level of interaction and understanding that approaches human-like comprehension of coding tasks. This flexibility in model selection, combined with Cursor's context-aware features, enables developers to tailor their AI assistance to the specific demands of each coding task.

For long-context chats, Cursor offers versions of these models with expanded context windows, allowing for even more comprehensive context understanding in complex projects.

Moreover, Cursor allows users to add custom API keys for various AI providers. This gives developers the flexibility to use their preferred models or to manage usage and costs according to their needs.

### Natural Language Interaction

One of Cursor's most powerful features is its ability to understand and respond to natural language queries. Developers can ask complex questions about their code, request explanations of specific functions, or even ask for suggestions on how to implement new features. This natural language interface makes it easier for developers to leverage AI assistance without having to learn a new syntax or command structure.

### CMD-K: Beyond Autocomplete

FIXME: Reference CMD-K here, that's what this is. Mention selecting code then asking for changes.

Cursor doesn't just suggest small code snippets; it can generate entire functions or classes based on natural language descriptions. Moreover, it can intelligently edit existing code, understanding the intent behind requested changes and implementing them across multiple files if necessary.

### Context-Aware Debugging

Cursor's AI can analyze error messages and stack traces in the context of your codebase, offering more insightful debugging suggestions. It can explain why an error is occurring and propose fixes that take into account the broader structure and logic of your project.

### Learning and Adaptation

Perhaps most impressively, Cursor learns from your coding style and project-specific conventions over time. This means that its suggestions become increasingly tailored to your personal or team coding practices, further enhancing its context-awareness.

Cursor represents a significant step forward in AI-assisted coding, demonstrating the power of context-aware AI in software development. By understanding not just individual lines of code but the broader context of entire projects, Cursor is helping developers work more efficiently and tackle more complex programming challenges.

## (Frontier) Gen 4 AI Coding: Unlimited Context with Developer-like Agentic Workflows
Featuring a lot of tools you can't use today

Andrew Ng on Agentic https://www.youtube.com/watch?v=sal78ACtGTc (zero shot) https://www.youtube.com/watch?v=q1XFm21I-VQ (feedback)

TODO: Here's a conversation with GPT-4o about the language to use in this section, and also key points to include. We arrived at "agent" / "agentic" as the best language to assemble this around.

INCLUDE: Planning

Start of chat ---
I'm working on an essay about AI coding. See the markdown doc for where I am now. 

I want to correctly describe what I'm currently calling "Next-gen AI Coding: Developer-like Agentic Processes"

I'm not sure whether to focus on "agent" / "agentic" or whether this is better described as "chain of thought" / "chain of reasoning". What are your thoughts? I don't need you to write or edit anything, just trying to best describe this coming generation of AI Coding tool capabilities.
ChatGPT said:
ChatGPT

For the "Next-gen AI Coding: Developer-like Agentic Processes" section of your essay, both "agent" / "agentic" and "chain of thought" / "chain of reasoning" are relevant concepts, but they emphasize different aspects of this new generation of AI coding tools.

    Agent / Agentic: This term focuses on the autonomy and independence of the AI tools. Describing these tools as "agentic" highlights their ability to act on their own, plan tasks, and make decisions similar to a human developer. This framing aligns well with the idea that these tools can handle complex tasks, understand project requirements, and execute them with minimal human intervention. It emphasizes the proactive, decision-making capabilities of AI, where the tools are not just responding to developer prompts but are autonomously moving through a sequence of steps or tasks to achieve a goal.

    Chain of Thought / Chain of Reasoning: These terms focus more on the cognitive process and logical flow that the AI follows to arrive at solutions. They are used in AI research to describe how models can simulate human-like reasoning, by breaking down complex tasks into simpler steps, considering alternatives, and progressing through a series of reasoned actions. This is important for AI tools that need to maintain a coherent approach over multiple steps, handle dependencies between tasks, or debug complex issues. This framing suggests that the AI's value comes from its ability to logically deduce or reason through the problems in a way that aligns with how human developers might think.

Which to Focus On?

    "Agent" / "Agentic" might be more appropriate if your emphasis is on the AI tools' capability to autonomously perform tasks and act in a developer-like role. It suggests a more holistic ability to handle development from start to finish, with minimal guidance.

    "Chain of Thought" / "Chain of Reasoning" would be fitting if you're focusing on the step-by-step process these tools use to solve problems or if you want to convey the logical, systematic nature of how they approach coding tasks. This framing could be useful if you want to emphasize the tools' ability to maintain context and coherence across complex, multi-step tasks.

Ultimately, the choice depends on the primary theme you want to convey: autonomy and decision-making ("agentic") versus logical problem-solving and process-based reasoning ("chain of thought"). Both are essential elements of the next-gen AI coding capabilities, so you might even consider integrating both concepts to capture a more comprehensive view.
You said:
There's one more aspect of this section that's critical. That is, "doing things the way I (the developer) would do them" ... the frontier tools in AI coding are all taking this approach. Does addressing this aspect fit better with "agent" / "agentic" or  "chain of thought" / "chain of reasoning"
ChatGPT said:
ChatGPT

The aspect of "doing things the way I (the developer) would do them" fits better with the "agent" / "agentic" framing.

Here's why:

    Agent / Agentic: This concept emphasizes an AI tool that acts in a way that mirrors a specific developer's style, preferences, and decision-making patterns. The idea of an "agent" inherently involves understanding and adapting to the environment or context in which it operates. In this case, the "environment" includes not only the codebase but also the unique habits, patterns, and preferences of the developer. An "agentic" AI tool would be designed to learn from a developer's behavior, understand their typical choices, and then replicate those choices autonomously when faced with similar tasks. It captures the sense of AI becoming a proxy or extension of the developer, performing tasks as if the developer were doing them.

    Chain of Thought / Chain of Reasoning: While this framing does involve systematic thinking and logical processes, it doesn't necessarily capture the personalized adaptation to a specific developer's style. "Chain of thought" or "chain of reasoning" focuses more on the internal cognitive process of the AI — how it logically arrives at solutions. It is less about mimicking a specific developer's style and more about maintaining coherence and logical progression through tasks. It does not inherently involve personalization or adaptation to a particular developer's unique methods or preferences.

Why "Agent / Agentic" is More Suitable

If you want to emphasize that these next-gen AI tools are not just executing tasks autonomously but doing so in a way that aligns with the developer's unique style and decision-making, the "agentic" framing is more fitting. It conveys the idea of the AI as a personalized assistant, one that learns and evolves to think and act in the same way the developer would, thereby making the collaboration feel more natural and effective.

By framing it around "agentic" AI, you capture both the autonomy of the tool and its ability to adapt and align with the developer’s unique approach, which seems to be a critical frontier in AI coding tools.
You said:
Two final topics I want to address here:
- The importance of the AI Coding agent getting feedback as to whether its code actually works, by building and running it
- The importance of the developer being able to see the AI Coding agent's work as it proceeds.
How do these fit in
ChatGPT said:
ChatGPT

These two topics—feedback on the AI agent's code execution and visibility into its ongoing work—fit well into the "agent" / "agentic" framework but can also touch on aspects of "chain of thought" / "chain of reasoning" in complementary ways.
How These Topics Fit with "Agent" / "Agentic":

    Feedback on Code Execution:
        Agent Autonomy and Learning: An "agentic" AI coding tool benefits significantly from direct feedback on whether its generated code works by building and running it. This feedback loop is crucial for the AI agent to learn, adapt, and refine its outputs in real-time. In this context, the AI agent is not just statically following instructions; it's actively engaged in a cycle of action, evaluation, and adjustment—much like a human developer who writes code, tests it, and revises it based on the results.
        Error Correction and Improvement: By receiving feedback, the AI agent can autonomously correct errors, optimize code, and enhance its future outputs. This process is analogous to how human developers learn from debugging and testing. The AI's ability to iterate based on feedback positions it as a dynamic, evolving "agent" that grows more effective over time, aligning its behaviors more closely with those of an experienced developer.

    Visibility into the AI Agent's Work:
        Transparency and Trust Building: When the developer can see the AI agent’s work as it progresses, it enhances trust and usability. This transparency is essential in ensuring that the developer understands what the AI is doing and why. It also allows the developer to intervene, guide, or correct the agent's actions as necessary, ensuring that the AI's work aligns with their expectations and coding standards.
        Collaborative Partnership: Viewing the AI’s ongoing work transforms the relationship between the developer and the AI from a "black box" process to a more collaborative partnership. The developer can see the thought process (or the chain of actions) the AI is following and can provide immediate feedback or adjustments, creating a dynamic, iterative workflow. This visibility also helps the developer feel in control of the AI's actions, enhancing the feeling that the AI is an "agent" acting on their behalf rather than an opaque tool making arbitrary decisions.

How These Topics Also Relate to "Chain of Thought" / "Chain of Reasoning":

    Feedback as a Validation of Reasoning:
        Ensuring Coherence and Logical Flow: In terms of "chain of thought," getting feedback from building and running code is essential for validating the AI's logical reasoning process. If the code doesn't run or produces errors, it indicates that there was a break in the chain of reasoning that needs to be addressed. This feedback helps the AI refine its reasoning steps to avoid similar mistakes in the future.
        Iterative Reasoning Improvement: Each time the AI receives feedback (such as a failed build or a bug in the code), it has an opportunity to improve its internal reasoning process. This aligns with the "chain of thought" concept by emphasizing the importance of logical consistency and the ability to adapt reasoning patterns based on results.

    Visibility into Reasoning Processes:
        Understanding AI Thought Patterns: When the developer can see the AI’s work in real-time, it provides insight into the AI's "chain of thought" or reasoning patterns. The developer can observe how the AI approaches a problem, which assumptions it makes, and what steps it follows. This transparency allows the developer to better understand the AI's reasoning process, potentially correcting or guiding it when it diverges from the desired path.
        Teaching and Fine-Tuning Reasoning: Visibility also allows developers to teach or fine-tune the AI's reasoning process. If the AI’s steps are visible, developers can provide direct feedback on specific reasoning flaws, enhancing the AI’s ability to think and act more like a human developer over time.

Conclusion

Both feedback and visibility are crucial components for the "agentic" nature of next-gen AI coding tools, enabling the AI to learn from its actions and build trust with developers. At the same time, they contribute to the "chain of thought" by validating and refining the AI's reasoning processes. Together, these aspects help create a more effective, reliable, and collaborative AI coding assistant that aligns closely with how human developers work and think.
--- End of chat


TODO: Mention Grit's lowering the floor vs raising the ceiling

This emerging trend in AI coding tools focuses on creating more autonomous, developer-like agents that can handle complex tasks with minimal human intervention. These tools aim to understand project requirements, break down tasks, and execute them in a way that mimics human developers' thought processes.

The AI coding landscape is rapidly evolving, with new tools emerging that promise to redefine how we approach software development:

- **[Devin](https://www.cognition-labs.com/)**: An AI software engineer capable of planning and executing complex programming tasks autonomously. Video demo: https://www.youtube.com/watch?v=T7NWjoD_OuY
- **[Cosine Genie](https://www.cosinegenie.com/)**: A tool that leverages AI to optimize code performance and efficiency. Video demo here: https://cosine.sh/genie
- **[Magic](https://magic.dev/)**: An AI-powered platform that aims to automate various aspects of software development, from ideation to deployment. Essay on 100M token context windows https://magic.dev/blog/100m-token-context-windows
- **[Poolside](https://www.poolside.ai/)**: A collaborative AI coding assistant that enhances team productivity and code quality.
- Codeium Video demo https://www.youtube.com/watch?v=DuZXbinJ4Uc
- **[Grit](https://www.grit.io/)**: An AI tool focused on improving code maintainability and reducing technical debt. 
- Replit Agent https://docs.replit.com/replitai/agent Video demo: https://www.youtube.com/watch?v=IYiVPrxY8-Y
- Honeycomb https://honeycomb.sh/  SWE-Bench post https://honeycomb.sh/blog/swe-bench-technical-report

While these tools are not yet widely available, they represent the cutting edge of AI in software development and hint at the future direction of the field. These agentic AI assistants are designed to take on more complex, end-to-end development tasks, potentially revolutionizing the role of human developers in the software creation process.

## Conclusion

As AI coding tools continue to evolve, their ability to understand and leverage context will likely be the key factor in their success. The emergence of more agentic, developer-like AI assistants promises to further revolutionize the software development process. These tools are not just changing how we write code, but how we think about the entire software development lifecycle, from planning to maintenance.

The challenge for developers will be to adapt to this new paradigm, learning to effectively collaborate with AI tools while maintaining critical thinking and high-level design skills. As we move forward, the most successful developers will likely be those who can harness the power of AI assistants while providing the creative and strategic insights that remain uniquely human.