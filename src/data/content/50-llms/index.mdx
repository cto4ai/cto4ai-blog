---
title: "Simon Willison's LLM Tool: Now I Have 50 LLMs"
contentType: 'brief'
description: "I updated my installation of Willison's LLM tool to add plugins, and now I have 50 LLMs at my fingertips, including 15 local models, which get installed on demand."
author: 'Jack Ivers'
publishDate: '2024-03-25T15:21:49-05:00'
draft: false
---

import SingleImage from '~/components/ui/SingleImage.astro';

I've been intending to get my feet wet with the [new Claude models](https://www.anthropic.com/news/claude-3-family) from Anthropic, especially Opus. When I saw Simon's [recent "sidequests" post](/p/two-from-willison) I decided to update to the latest version of his [LLM CLI tool](https://llm.datasette.io/en/stable/) (part of [Datasette](https://datasette.io/)) and get Opus access from the command line, using the Claude plugin.

While I was at it, I connected Google Gemini, Anyscale Endpoints, and gpt4all, the latter providing the abovementioned 15 local models, which auto-install when you first request a model. 50 LLMs in all---and this is far from the [complete list](https://llm.datasette.io/en/stable/plugins/directory.html) LLM provides access to through its plugin architecture.

<SingleImage src="50-models-better.png" alt="50-models-better.png" size="xl" postDir="50-llms" />

Very handy for testing, such as "how does Llama 70b compare to ChatGPT GPT-4 on this question?"
