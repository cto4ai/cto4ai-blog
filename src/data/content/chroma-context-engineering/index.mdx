---
title: "Chroma: RAG is Dead-Long Live Context Engineering"
contentType: "episode"
description: "Exploring how Chroma is revolutionizing context engineering and moving beyond traditional RAG approaches"
author: "Jack Ivers"
publishDate: "2025-09-07T14:13:00-05:00"
image: "~/assets/images/content/chroma-context-engineering/cover-image.png"
featured: false
draft: true
tags: ["ai", "rag", "chroma", "context-engineering", "vector-databases"]
categories: ["ai-and-technology"]
---

import SingleImage from '~/components/ui/SingleImage.astro';
import ImageGallery from '~/components/ui/ImageGallery.astro';
import ChatTranscript from '~/components/ui/ChatTranscript.astro';

## Introduction

If RAG (Retrieval Augmented Generation) is dead, then what's alive? What's the right way of thinking about and exposing company knowledge through AIs? This episode of the Latent Space poscast, featuring Chroma CEO and cofounder Jeff Huber, has compelling answers.

## What & Who is Chroma?

[Chroma](https://github.com/chroma-core/chroma) is an open-source embedding database purpose-built for LLM applications. The company was founded in 2022 by Jeff Huber (CEO) and Anton Troynikov.

### Core Purpose

Chroma lets developers store embeddings alongside metadata and associated text, then run fast similarity search with filtering to ground LLM outputs in relevant, verifiable context—reducing hallucinations and improving answer quality.

### Core Features

- Vector similarity search over collections
- Metadata filtering for precise retrieval
- Persistent storage for vectors, metadata, and associated text
- Official client libraries: Python and JavaScript/TypeScript (first‑party); additional clients for Ruby, Java, Go, C#, Elixir, and Rust
- Embedding-agnostic: works with text and other modalities via embeddings

### Extended Features and Commercial Offerings

Beyond the core open-source capabilities, Chroma offers **Chroma Distributed**—an open-source, distributed version built in Rust that enables multi-node deployments for scalability and high-throughput requirements. For teams seeking a fully managed solution, **Chroma Cloud** provides a serverless, distributed architecture that abstracts infrastructure complexity while supporting deployment across major cloud platforms (AWS, GCP, Azure).

## Snip: RAG => Context Engineering

Huber detests the term "RAG" and his opinions on the topic helped convince Swyx to remove the RAG track from the AI Engineer World's Fair event in June.

<SingleImage src="snip_quote_snip_quote_3a87c36a_e18e_4081_bfd6_84f563afab93_1757294738179.png" alt="Jeff Huber defining context engineering" postDir="chroma-context-engineering" />

 He describes in [this snip](https://share.snipd.com/snip/3a87c36a-e18e-4081-bfd6-84f563afab93) what I believe is a far better framing of the core issue and solution---context engineering.

<video controls width="100%">
  <source src="/videos/content/chroma-context-engineering/snip_video_snip:3a87c36a-e18e-4081-bfd6-84f563afab93.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

## Snip: Context Rot

Model builders like OpenAI, Anthropic, and Google DeepMind keep announcing increasingly large context windows, to 1M tokens and beyond. And with contexts getting larger and larger, who needs a retrieval solution like Chroma?

<SingleImage src="episode_transcript_quote_episode_transcript_quote_e915ab63_dc66_454d_b9b6_af4a4739e72c_1757294241344.png" alt="Jeff Huber quote about context window implications" postDir="chroma-context-engineering" />

But there's a dirty little secret known mainly among researchers---context rot. When a large context gets operated on repeatedly, for example in multi-turn agent interactions, the context "rots," and the model effectively loses its mind, most seriously the failure to follow clearly-stated instructions. Chroma researched this problem carefully, and in [this snip](https://share.snipd.com/snip/8fa58784-da31-41d4-ba9d-f0891d8a9283), Huber describes what they discovered.

<video controls width="100%">
  <source src="/videos/content/chroma-context-engineering/snip_video_snip_8fa58784-da31-41d4-ba9d-f0891d8a9283.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

## Snip: Context Chunk Selection and LLM Re-ranking

Huber and Chroma definitely have their finger on the pulse of "latest context engineering tips and tricks" ...

<SingleImage src="episode_transcript_quote_episode_transcript_quote_e915ab63_dc66_454d_b9b6_af4a4739e72c_1757295888624.png" alt="Context chunk selection process" postDir="chroma-context-engineering" />

In [this snip](https://share.snipd.com/snip/f1faab7a-3205-4a1f-ab6c-f10be993b359) he shares emerging practices around getting from 1M or 100K down to 30 using LLM brute-forcing.

<video controls width="100%">
  <source src="/videos/content/chroma-context-engineering/snip_video_snip_f1faab7a-3205-4a1f-ab6c-f10be993b359.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

## Snip: Code Embeddings

Blah blah

<SingleImage src="episode_transcript_quote_episode_transcript_quote_e915ab63_dc66_454d_b9b6_af4a4739e72c_1757297455202.png" alt="Code embeddings discussion" postDir="chroma-context-engineering" />

Blah link 
[Code Embeddings (30sec)](https://share.snipd.com/snip/f62bdafa-407e-41be-8120-e977cf43bf43)

<video controls width="100%">
  <source src="/videos/content/chroma-context-engineering/snip_video_snip_f62bdafa-407e-41be-8120-e977cf43bf43.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>


