I recently wrote about Jeff Huber, Chroma, and Context Engineering; and highlighted Chroma's research into the phenomenon of "context rot."

Just this morning, I noticed this point reinforced in a Hacker News comment thread. User gizmodo59 noted: "My take on long context for many frontier models is not about support but the accuracy drops drastically as you increase the context. Even if a model claims to support 10M context, reality is it doesn't perform well when you saturate."

User kridsdale3 responded: "This is my experience with Gemini. Yes, I really can put an entire codebase and all the docs and pre-dev discussions and all the inter-engineer chat logs in there. I still see the model becoming more intoxicated as turn count gets high."

The AI companies keep promoting bigger context windows like they're the solution to everything. But large contexts don't actually work yet, as gizmodo59 notes, "when you saturate." Which is exactly what multi-turn agent interactions do. 

https://cto4.ai/p/chroma-context-engineering

gizmodo59's comment: https://news.ycombinator.com/item?id=45221099
kridsdale3's comment: https://news.ycombinator.com/item?id=45221318
